{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Data Collection\n",
    "\n",
    "This is a **project group assignment** with the teams already established."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project E: Simple Object Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each team must **record at least 100 videos, each 3-seconds long**. We recommend collecting evenly number of samples per class, in this case, **20 videos per class (ball, mug, pen, spoon, notebook)**. Videos should be stored as *.mov* or *.mp4* format, and 15 frames from each video must include a bounding box annotation alongside its label. After data collection, all teams’ data will be merged, preprocessed, and split into training and test sets.\n",
    "\n",
    "* **Note:** We will assume that all videos were collected with 30 fps (frames per second) camera.\n",
    "\n",
    "The **ambient sound labels** are: \n",
    "* ball - Label 1\n",
    "* mug - Label 2\n",
    "* pen - Label 3\n",
    "* spoon - Label 4 \n",
    "* notebook - Label 5\n",
    "\n",
    "We recommend you to save your files using a **coding system**, e.g. **ID-trial-label**. First give a number from 1 to 3 to each team member, this is the ID. Then, for example, when team member with ID 2 is recording hers/his/their 3rd video of moving notebook (label 5), the file name should read \"2-3-5.mov\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Save frames for Annotation\n",
    "\n",
    "The code below reads a folder containing all your .mov or .mp4 files and saves each video’s 15 extracted frames into a separate folder.\n",
    "\n",
    "You will then use these frames to annotate the object’s bounding box in each image (see step 4 below).\n",
    "\n",
    "Before running the code, make sure to update the variable ```mydir``` with the directory path where your video recordings are stored as well as the csv annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "# CHANGE ME!\n",
    "# mydir = 'change-this-to-your-data-directory-local-path\n",
    "mydir = 'videos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for file in os.listdir(mydir):\n",
    "    if file.endswith((\".mp4\", \".MOV\", \".mov\")):  # only read video files\n",
    "        filename = os.path.join(mydir, file)\n",
    "        cap = cv2.VideoCapture(filename)\n",
    "\n",
    "        # Parameters\n",
    "        fps = 30\n",
    "        target_fps = 5\n",
    "        frame_interval = int(fps / target_fps)  # capture 1 out of every 6 frames\n",
    "        max_frames = int(3 * target_fps)        # 3 seconds × 5 fps = 15 frames\n",
    "\n",
    "        # Create output folder for this video\n",
    "        video_name = os.path.splitext(file)[0]\n",
    "        output_dir = os.path.join(mydir, video_name)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        frame_count = 0\n",
    "        saved_frames = 0\n",
    "        frames = []\n",
    "        while cap.isOpened() and saved_frames < max_frames:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (100, 100))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "            frame_filename = os.path.join(output_dir, f\"frame_{saved_frames:02d}.png\")\n",
    "            cv2.imwrite(frame_filename, cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR))\n",
    "            frame_count += 1\n",
    "            saved_frames += 1\n",
    "\n",
    "        # Convert to numpy array (frames, height, width, channels)\n",
    "        video_array = np.array(frames, dtype=np.uint8)\n",
    "\n",
    "        if i==0:\n",
    "            data = video_array\n",
    "        else:\n",
    "            data = np.stack((data, video_array), axis=0)\n",
    "\n",
    "        cap.release()\n",
    "        print(f\"Saved {saved_frames} frames from {file} to {output_dir}\")\n",
    "        i+=1\n",
    "\n",
    "print('----------------------DONE-----------------------------')\n",
    "\n",
    "# Saves the files to your current directory\n",
    "np.save('data', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that the data saved all 100 videos. \n",
    "# The shape of data should be Nx15x100x100x3\n",
    "# where N is the number of samples, N=100.\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Data Annotation\n",
    "\n",
    "Use [makesense.ai](https://www.makesense.ai/) to annotate each frame in the video.\n",
    "1. Click on \"Get Started\" (bottom right corner).\n",
    "2. Import the frames from one video folder (this must be repeated for all 100 videos).\n",
    "3. Select \"Object Detection\".\n",
    "4. Click \"Start Project\".\n",
    "5. For each frame, use the cursor to draw a bounding box around the object, and select the appropriate label.\n",
    "    * For ball use 1, mug use 2, pen use 3, spoon use 4, and notebook use 5.\n",
    "6. Click \"Actions\" (yop left), then \"Export Annotations\" as a **csv** file. **Important:** rename the csv file with the same name as video file and its frames folder (e.g. 1-2-4.mov, 1-2-4.csv, and 1-2-4 folder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Prepare Your Data for Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to save the annotations labels as a single ```csv``` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE ME!\n",
    "\n",
    "csv_dir = 'change-this-to-your-csv-directory-local-path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "# Expected columns in each CSV from makesense.ai\n",
    "columns = [\"label_name\", \"bbox_x\", \"bbox_y\", \"bbox_width\", \"bbox_height\",\n",
    "    \"image_name\", \"image_width\", \"image_height\"]\n",
    "\n",
    "for file in os.listdir(csv_dir):\n",
    "    if file.endswith(\".csv\"):\n",
    "        filepath = os.path.join(csv_dir, file)\n",
    "        df = pd.read_csv(filepath, usecols=columns)  # load only expected columns\n",
    "        df[\"filename\"] = os.path.splitext(file)[0]\n",
    "        df_list.append(df)\n",
    "\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "merged_df.to_csv(os.path.join(csv_dir, \"team_annotations.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Upload Your Data in Canvas\n",
    "\n",
    "To receive full credit in this question, you should submit to Canvas all of the following files:\n",
    "\n",
    "1. Compressed folder (.zip) with the videos from all team members. (100 videos per team should be included.)\n",
    "2. File \"data.npy\"\n",
    "3. File \"team_annotations.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit your Solution\n",
    "\n",
    "Confirm that you've successfully completed the assignment.\n",
    "\n",
    "```add``` and ```commit``` the final version of your work, and ```push``` your code/data to your GitHub repository -- **you may run into memory issues. If this happens, disregard this step and only submit the data files to Canvas**\n",
    "\n",
    "Submit the URL of your GitHub Repository along with all data as your assignment submission on Canvas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
